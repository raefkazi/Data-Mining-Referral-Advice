# -*- coding: utf-8 -*-
"""DS_RA_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oN3vZ41K0TTK7ISBa9gfVtkG5Njt3r23

# Final Data Preprocessing

## Read data
"""

import pandas as pd
import numpy as np

import io
import pandas as pd
from google.colab import files

uploaded = files.upload()

df = pd.read_excel(io.BytesIO(uploaded.get("Dataset - LBP RA.xlsx")),  sheet_name = "Training Dataset")
var = pd.read_excel(io.BytesIO(uploaded.get("Dataset - LBP RA.xlsx")),  sheet_name = "Variables")

df.head()

(df.count()/1546*100).sort_values()

"""## Dropping columns with more than 15% missing values"""

df_new = df.drop("Irrational_thoughts_work",1)
df_new = df_new.drop("Incoordination",1)
df_new = df_new.drop("Relationship_with_colleagues",1)
df_new = df_new.drop("Trauma",1)
df_new = df_new.drop("working_ability",1)
df_new = df_new.drop("Workoverload",1)

"""##Visualize missing values"""

#Data Completeness percentage
df2 = (df.count()/1546*100).sort_values().rename_axis('Features').reset_index(name='counts')
df2.set_index('Features')
df_filtered = df2[df2['counts'] < 100]
df_filtered

#df_filtered = df_filtered[df_filtered[100-'counts']]
df_filtered['inverted'] = 100-df_filtered.counts
df_filtered

#create bar chart
import matplotlib.pyplot as plt

y_axis = df_filtered['Features']
x_axis = df_filtered['counts']

plt.barh (y_axis, x_axis)
plt.title('Features and percentage of values present in the data')
plt.ylabel('Feature')
plt.xlabel('Percentage of data missing')
plt.show()

#create bar chart
import matplotlib.pyplot as plt

y_axis = df_filtered['Features']
x_axis = df_filtered['inverted']

plt.barh (y_axis, x_axis)
plt.title('Features and percentage of values missing in the data')
plt.ylabel('Feature')
plt.xlabel('Percentage of data missing')
plt.show()

df_new.columns

"""## Impute Missing Values

###One-hot Encoding Age column
"""

#One-hot encode age
#One hot encoding
from numpy import array
from numpy import argmax
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

#Age encoding
df_new['age_ohe'] = array(df_new['Age'])
#integer encode
label_encoder = LabelEncoder()
age_encoded = label_encoder.fit_transform(df_new['age_ohe'])
df_new['age_ohe'] = array(age_encoded)

#Dropping original Age column
df_new = df_new.drop("Age",1)

"""### Iterative Imputer"""

# iterative imputation transform
from numpy import isnan
from pandas import read_csv
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

data = df_new.values
ix = [i for i in range(data.shape[1]) if i != 0]
X, y = data[:, ix], data[:, 0]
# print total missing
print('Missing: %d' % sum(isnan(X).flatten()))
# define imputer
imputer = IterativeImputer(max_iter = 50, skip_complete = True)
# fit on the dataset
imputer.fit(X)
# transform the dataset
Xtrans = imputer.transform(X)
# print total missing
print('Missing: %d' % sum(isnan(Xtrans).flatten()))

from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
# define modeling pipeline
model = RandomForestClassifier()
imputer = IterativeImputer()
pipeline = Pipeline(steps=[('i', imputer), ('m', model)])

from numpy import mean
from numpy import std
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
# define model evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate model
scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')
print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

feature_cols = ['Fever', 'Duration_of_pain', 'Sick_leave',
       'Earlier_hospitalization', 'Familiy_history', 'Depression',
       'Extremely_nervous', 'Stress', 'Irrational_thoughts_risk_lasting',
       'Coping_strategy', 'Kinesiophobia_physical_exercise',
       'Kinesiophobia_pain_stop', 'Uses_analgesics',
       'Uses_corticosteroids', 'Serious_disease', 'Neurogenic_signals',
       'Continuous_pain', 'Decreased_mobility', 'Nocturnal_pain',
       'Weightloss_per_year', 'Loss_muscle_strength', 'Failure_symptoms',
       'neck_pain_intensity', 'low_back_pain_intensity',
       'arm_left_pain_intensity', 'arm_right_pain_intensity',
       'leg_left_pain_intensity', 'leg_right_pain_intensity', 'Paidwork',
       'age_ohe']
X = df_new[feature_cols] # Features
y = df_new.Treatment # Target variable

X = pd.DataFrame(Xtrans, columns = feature_cols)

"""##Standard Scaling Data"""

from sklearn.preprocessing import StandardScaler
x = X.loc[:, feature_cols].values
#y = df_new.loc[:,['Treatment']].values
x = StandardScaler().fit_transform(x)
X = pd.DataFrame(x, columns = feature_cols)

X

"""## Over and Undersampling"""

# Generate and plot a synthetic imbalanced classification dataset
from collections import Counter
from sklearn.datasets import make_classification
from matplotlib import pyplot
from numpy import where
from imblearn.over_sampling import SMOTE

"""###Visualize class imbalance"""

# summarize class distribution
counter = Counter(y)
print(counter)

df_counter = pd.DataFrame.from_dict(counter, orient='index').reset_index()
#create Pie chart
from matplotlib import pyplot as plt
import numpy as np
 
# Creating dataset
features = df_counter['index']

data = df_counter[0]
 
# Creating plot
fig = plt.figure(figsize =(10, 7))
plt.pie(data, labels = features)
 
# show plot
plt.show()

from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline

over = SMOTE()
under = RandomUnderSampler()

steps = [('o', over), ('u', under)]
pipeline = Pipeline(steps=steps)

# transform the dataset
X, y = pipeline.fit_resample(X, y)

# summarize the new class distribution
counter = Counter(y)
print(counter)

"""#Feature analysis

##PCA
"""

from sklearn.decomposition import PCA

pca_model = PCA(n_components=10).fit(X)
X_pc = pca_model.transform(X)

# number of components
n_pcs= pca_model.components_.shape[0]

# get the index of the most important feature on EACH component
# LIST COMPREHENSION HERE
most_important = [np.abs(pca_model.components_[i]).argmax() for i in range(n_pcs)]
initial_feature_names = feature_cols
# get the names
most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]
# LIST COMPREHENSION HERE AGAIN
dic = {'PC{}'.format(i): most_important_names[i] for i in range(n_pcs)}
# build the dataframe
pca_mostimp = pd.DataFrame(dic.items())

pca_mostimp

X_selection_pca = X[["Fever", "Decreased_mobility", "Kinesiophobia_pain_stop","leg_left_pain_intensity", "Duration_of_pain", "arm_left_pain_intensity", "Stress","Coping_strategy" ]]

X_selection_pca

# split data into train and test sets
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X_selection_pca, y, test_size=test_size, random_state=seed)

pca_model.explained_variance_ratio_

"""###Random forest"""

# Random  forest
from sklearn.ensemble import RandomForestClassifier
# Instantiate model with 1000 decision trees
rf_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)
# Train the model on training data
rd_model = rf_model.fit(X_train, y_train)

# make predictions for test data
y_pred = rf_model.predict(X_test)
predictions = [round(value) for value in y_pred]
# Calculate the absolute errors
errors = abs(predictions - y_test)
# Print out the mean absolute error (mae)
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

# evaluate predictions
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, predictions)
cnf_matrix

#classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

"""##Recursive feature elimination"""

# Feature Extraction with RFE
from pandas import read_csv
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

# feature extraction
model = LogisticRegression(solver='lbfgs', max_iter = 500)
rfe = RFE(model, n_features_to_select = 10)
fit = rfe.fit(X, y)
print("Num Features: %d" % fit.n_features_)
print("Selected Features: %s" % fit.support_)
print("Feature Ranking: %s" % fit.ranking_)

for feature in fit.support_.nonzero():
  print(X.columns[feature])

X_selection_rfe = X[X.columns[feature]]
X_selection_rfe

# split data into train and test sets
seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X_selection_rfe, y, test_size=test_size, random_state=seed)

"""###Random forest"""

# Random  forest
from sklearn.ensemble import RandomForestClassifier
# Instantiate model with 1000 decision trees
rf_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)
# Train the model on training data
rd_model = rf_model.fit(X_train, y_train)

# make predictions for test data
y_pred = rf_model.predict(X_test)
predictions = [round(value) for value in y_pred]
# Calculate the absolute errors
errors = abs(predictions - y_test)
# Print out the mean absolute error (mae)
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

# evaluate predictions
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, predictions)
cnf_matrix

#classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

"""###XGBoost"""

from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# fit model no training data
model = XGBClassifier()
model.fit(X_train, y_train)

# make predictions for test data
y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""###K-Fold Cross Validation"""

from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# prepare the cross-validation procedure
cv = KFold(n_splits=10, random_state=1, shuffle=True)

# evaluate model
scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
# report performance
print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

"""##Univariate selection"""

# Feature Selection with Univariate Statistical Tests
from pandas import read_csv
from numpy import set_printoptions
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
# feature extraction
test = SelectKBest(score_func=f_classif, k=8)
fit = test.fit(X, y)
# summarize scores
set_printoptions(precision=3)
print(fit.scores_,)
features = fit.transform(X)
# summarize selected features
print(features[0:5,:])

#import needed packages
from sklearn.datasets import load_digits
import pandas as pd
from sklearn.feature_selection import SelectKBest, chi2

#X, y = load_digits(return_X_y=True)
#df = pd.DataFrame(X, columns= ['feaure %s'%i for i in range(X.shape[1])])

# feature extraction
test = SelectKBest(score_func=f_classif, k=10)
fit = test.fit(X, y)
# summarize scores
set_printoptions(precision=3)
print(fit.scores_,)
features = fit.transform(X)
X.shape
X.columns[fit.get_support()]

from sklearn.datasets import load_digits
import pandas as pd
from sklearn.feature_selection import SelectKBest, chi2

#apply SelectKBest class to extract top 10 best features
#bestfeatures = SelectKBest(score_func=chi2, k=10)
#fit = bestfeatures.fit(X,y)
# feature extraction
test = SelectKBest(score_func=f_classif, k=10)
fit = test.fit(X, y)

dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(X.columns)
#concat two dataframes for better visualization 
featureScores = pd.concat([dfcolumns,dfscores],axis=1)
featureScores.columns = ['Specs','Score']  #naming the dataframe columns
print(featureScores.nlargest(30,'Score'))  #print 10 best features

X_selected_univariate = X[X.columns[fit.get_support()]]

# split data into train and test sets
seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X_selected_univariate, y, test_size=test_size, random_state=seed)

"""## Feature importance from random forest"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# split data into train and test sets
seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)

# Random  forest
from sklearn.ensemble import RandomForestClassifier
# Instantiate model with 1000 decision trees
rf_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)
# Train the model on training data
rd_model = rf_model.fit(X_train, y_train)

# make predictions for test data
y_pred = rf_model.predict(X_test)
predictions = [round(value) for value in y_pred]
# Calculate the absolute errors
errors = abs(predictions - y_test)
# Print out the mean absolute error (mae)
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, predictions)
cnf_matrix

#classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

"""###Obtaining feature importance and selecting features"""

# Let's load the packages
import numpy as np
import pandas as pd
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import permutation_importance
#import shap
from matplotlib import pyplot as plt
plt.barh(X.columns, rf_model.feature_importances_)

sorted_idx = rf_model.feature_importances_.argsort()
plt.barh(X.columns[sorted_idx], rf_model.feature_importances_[sorted_idx])
plt.xlabel("Random Forest Feature Importance")
plt.figure(figsize=(2, 2))

rf_features = pd.DataFrame(X.columns[sorted_idx])
rf_scores = pd.DataFrame(rf_model.feature_importances_[sorted_idx])
rf_features['Scores'] = rf_scores
rf_features['Features']=rf_features[0]
rf_features = rf_features.nlargest(10, 'Scores')['Features']
rf_features

X_selected_rf = X[['age_ohe', 'Decreased_mobility', 'Kinesiophobia_physical_exercise', 'Extremely_nervous', 'Coping_strategy', 'low_back_pain_intensity','Irrational_thoughts_risk_lasting','leg_left_pain_intensity', 'leg_right_pain_intensity', 'Kinesiophobia_pain_stop']]

#obtaining feature importance using permutation from random forest: (second method to obtain feature importnance)
#this is computationally very extensive!!
#from sklearn.inspection import permutation_importance
#perm_importance = permutation_importance(rf_model, X_test, y_test)
#sorted_idx = perm_importance.importances_mean.argsort()
#plt.barh(X.columns[sorted_idx], perm_importance.importances_mean[sorted_idx])
#plt.xlabel("Permutation Importance")

"""### Random forest with selected features from Random forest featre importance"""

# split data into train and test sets
from sklearn.model_selection import train_test_split
seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X_selected_rf, y, test_size=test_size, random_state=seed)

# Random  forest
from sklearn.ensemble import RandomForestClassifier
# Instantiate model with 1000 decision trees
rf_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)
# Train the model on training data
rd_model = rf_model.fit(X_train, y_train)

# make predictions for test data
y_pred = rf_model.predict(X_test)
predictions = [round(value) for value in y_pred]
# Calculate the absolute errors
errors = abs(predictions - y_test)
# Print out the mean absolute error (mae)
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, predictions)
cnf_matrix

#classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

"""###Decision Tree with random forest top 10 features

"""

#Decision tree
from sklearn.tree import DecisionTreeClassifier
# Create Decision Tree classifer object
dt_model = DecisionTreeClassifier()
# Fit data to Decision Tree Classifer
dt_model = dt_model.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = dt_model.predict(X_test)
#round values of y_pred
dt_predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, dt_predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

#show the performance of the decision tree classification model using the classification_report
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""###XGBoost with random forst top ten features"""

from xgboost import XGBClassifier
# fit model no training data
model = XGBClassifier()
model.fit(X_train, y_train)

# make predictions for test data
y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""###K Fold cross validation

"""

from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# prepare the cross-validation procedure
cv = KFold(n_splits=10, random_state=1, shuffle=True)

# evaluate model
scores = cross_val_score(dt_model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
# report performance
print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

"""#Final Feature selection

"""

final_selection = pd.DataFrame(['Duration_of_pain', 'Sick_leave', 'Familiy_history',
       'Kinesiophobia_physical_exercise', 'neck_pain_intensity',
       'arm_right_pain_intensity', 'leg_left_pain_intensity',
       'leg_right_pain_intensity', 'Paidwork', 'age_ohe','Fever', 'Familiy_history', 'Uses_analgesics', 'Serious_disease',
       'Continuous_pain', 'neck_pain_intensity', 'arm_left_pain_intensity',
       'arm_right_pain_intensity', 'leg_left_pain_intensity', 'age_ohe','Uses_corticosteroids', 'Serious_disease', 'neck_pain_intensity',
       'Neurogenic_signals', 'Kinesiophobia_physical_exercise', 'age_ohe',
       'Nocturnal_pain', 'Paidwork', 'leg_left_pain_intensity',
       'Extremely_nervous'])

final_selection = final_selection.drop_duplicates().reset_index()
final_selection

"""# Model Comparison for classification on 5 classes"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# split data into train and test sets
seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)

"""##XGBoost"""

from xgboost import XGBClassifier
# fit model no training data
model = XGBClassifier(n_estimators = 200)
model.fit(X_train, y_train)

# make predictions for test data
y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""###K-Fold Cross Validation"""

from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# prepare the cross-validation procedure
cv = KFold(n_splits=10, random_state=1, shuffle=True)

# evaluate model
scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
# report performance
print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

"""##Logistic Regression"""

#Logistic Regression
from sklearn.linear_model import LogisticRegression
# instantiate the model (using the default parameters)
logreg = LogisticRegression()
# fit the model with data (Train)
lr_model = logreg.fit(X_train,y_train)

#make predictions using test data
y_pred=logreg.predict(X_test)
#round values of y_pred
lr_predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, lr_predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

#show the performance of the logistic regression classification model using the classification_report
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""###K Fold cross validation"""

from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# prepare the cross-validation procedure
cv = KFold(n_splits=10, random_state=1, shuffle=True)

# evaluate model
scores = cross_val_score(lr_model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
# report performance
print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

"""##Decision Tree

"""

#Decision tree
from sklearn.tree import DecisionTreeClassifier
# Create Decision Tree classifer object
dt_model = DecisionTreeClassifier()
# Fit data to Decision Tree Classifer
dt_model = dt_model.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = dt_model.predict(X_test)
#round values of y_pred
dt_predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, dt_predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

#show the performance of the decision tree classification model using the classification_report
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
from sklearn import tree
plt.figure(figsize=(12,12))
tree.plot_tree(dt_model, fontsize=10)
plt.show()

"""###K Fold cross validation

"""

from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# prepare the cross-validation procedure
cv = KFold(n_splits=10, random_state=1, shuffle=True)

# evaluate model
scores = cross_val_score(dt_model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
# report performance
print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

"""##Random Forest"""

# Random  forest
from sklearn.ensemble import RandomForestClassifier
# Instantiate model with 1000 decision trees
rf_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)
# Train the model on training data
rd_model = rf_model.fit(X_train, y_train)

# make predictions for test data
y_pred = rf_model.predict(X_test)
predictions = [round(value) for value in y_pred]
# Calculate the absolute errors
errors = abs(predictions - y_test)
# Print out the mean absolute error (mae)
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, predictions)
cnf_matrix

#classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

"""###K Fold cross validation"""

from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# prepare the cross-validation procedure
cv = KFold(n_splits=10, random_state=1, shuffle=True)

# evaluate model
scores = cross_val_score(rf_model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
# report performance
print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

"""## Support Vector Machine"""

#SVM
#Support Vector Machine
from sklearn import metrics
from sklearn.svm import SVC
# fit a SVM model to the data
svm_model = SVC()
svm_model.fit(X_train, y_train)

# make predictions for test data
y_pred = svm_model.predict(X_test)
predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, predictions)
cnf_matrix

#classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

"""###K-Fold Cross Validation"""

from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# prepare the cross-validation procedure
cv = KFold(n_splits=10, random_state=1, shuffle=True)

# evaluate model
scores = cross_val_score(svm_model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
# report performance
print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

"""#Reduced Features Comparison"""

"""
#from XGBoost suggested columns
feature_cols_new = ['Uses_corticosteroids', 'Serious_disease', 'neck_pain_intensity',
       'Neurogenic_signals', 'Kinesiophobia_physical_exercise', 'age_ohe',
       'Nocturnal_pain', 'Paidwork', 'leg_left_pain_intensity',
       'Extremely_nervous']
"""
"""
#Univariate Selection columns
feature_cols_new = ['age_ohe', 'leg_left_pain_intensity', 'neck_pain_intensity',
       'leg_right_pain_intensity', 'Paidwork',
       'Familiy_history', 'Duration_of_pain',
       'arm_right_pain_intensity', 'Kinesiophobia_physical_exercise', 'Sick_leave']
"""
"""
#PCA columns
feature_cols_new = ['Fever', 'Decreased_mobility', 'Kinesiophobia_pain_stop',
       'leg_left_pain_intensity','Duration_of_pain',
       'arm_left_pain_intensity','Loss_muscle_strength',
       'Irrational_thoughts_risk_lasting', 'Stress', 'Weightloss_per_year'
       ]
"""
"""
#Tweaked PCA columns
feature_cols_new = ['Fever', 'Decreased_mobility', 'Kinesiophobia_pain_stop',
       'leg_left_pain_intensity','Duration_of_pain',
       'arm_left_pain_intensity','age_ohe'
       ]

"""
"""
#Column vs accuracy comparison
"""
"""
feature_cols_new = ['age_ohe', 'leg_right_pain_intensity', 'neck_pain_intensity',
      'leg_left_pain_intensity','Duration_of_pain','low_back_pain_intensity','Fever',
      'Paidwork','Familiy_history','arm_right_pain_intensity', 'Sick_leave','Uses_corticosteroids',
      'Serious_disease', 'Kinesiophobia_physical_exercise', 'Neurogenic_signals', 'Coping_strategy',
      'Nocturnal_pain', 'arm_left_pain_intensity','Loss_muscle_strength', 'Irrational_thoughts_risk_lasting',
      'Stress','Earlier_hospitalization', 'Failure_symptoms','Uses_analgesics', 'Kinesiophobia_pain_stop',
      'Depression','Continuous_pain','Extremely_nervous','Weightloss_per_year','Decreased_mobility'
      ]
"""
#final selection: 7 features, 64.7% accuracy -> added 1 more from RF feature importnance :  'Decreased_mobility'
feature_cols_new = ['age_ohe', 'leg_right_pain_intensity', 'neck_pain_intensity',
       'leg_left_pain_intensity','Duration_of_pain',
       'low_back_pain_intensity','Fever']

#feature_cols = ['Duration_of_pain', 'Kinesiophobia_physical_exercise', 'Kinesiophobia_pain_stop', 'Continuous_pain', 'neck_pain_intensity', 'leg_left_pain_intensity', 'age_ohe']
X_new = X[feature_cols_new] # Features
#X_new = X[X.columns.difference(feature_cols_new)]
y_new = y # Target variable

len(X_new.columns)

X_new.columns

# split data into train and test sets
from sklearn.model_selection import train_test_split
seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=test_size, random_state=seed)

corr = X_new.corr()

import seaborn as sns
sns.heatmap(corr)

"""##Random Forest"""

# Random  forest
from sklearn.ensemble import RandomForestClassifier
# Instantiate model with 1000 decision trees
rf_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)
# Train the model on training data
rd_model = rf_model.fit(X_train, y_train)

# make predictions for test data
y_pred = rf_model.predict(X_test)
predictions = [round(value) for value in y_pred]
# Calculate the absolute errors
errors = abs(predictions - y_test)
# Print out the mean absolute error (mae)
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

# evaluate predictions
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, predictions)
cnf_matrix

#classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

"""## Support Vector Machine"""

#SVM
#Support Vector Machine
from sklearn import metrics
from sklearn.svm import SVC
# fit a SVM model to the data
svm_model = SVC()
svm_model.fit(X_train, y_train)

# make predictions for test data
y_pred = svm_model.predict(X_test)
predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, predictions)
cnf_matrix

#classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

"""##XGBoost """

# split data into train and test sets
#seed = 7
#test_size = 0.33
#X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=test_size, random_state=seed)

# fit model no training data
xg_model = XGBClassifier(n_estimators = 200)
xg_model.fit(X_train, y_train)

# make predictions for test data
y_pred = xg_model.predict(X_test)
predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""#Binary classification using classes 1 and 5

##Pre-processing of data
"""

#select data for only classes 1 and 5

"""### Read data"""

df = pd.read_excel(io.BytesIO(uploaded.get("Dataset - LBP RA.xlsx")),  sheet_name = "Training Dataset")
var = pd.read_excel(io.BytesIO(uploaded.get("Dataset - LBP RA.xlsx")),  sheet_name = "Variables")

"""### Dropping columns with more than 15% missing values"""

#Data Completeness percentage
(df.count()/1546*100).sort_values()

df_new = df.drop("Irrational_thoughts_work",1)
df_new = df_new.drop("Incoordination",1)
df_new = df_new.drop("Relationship_with_colleagues",1)
df_new = df_new.drop("Trauma",1)
df_new = df_new.drop("working_ability",1)
df_new = df_new.drop("Workoverload",1)

"""###Select data with output classes 1 and 5

"""

df_twoclasses = df_new[(df_new.Treatment != 2) & (df_new.Treatment != 3) & (df_new.Treatment != 4)]

df_twoclasses.Treatment.unique()

"""### Impute Missing Values

#####One-hot Encoding Age column
"""

#One-hot encode age
#One hot encoding
from numpy import array
from numpy import argmax
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

#Age encoding
df_twoclasses['age_ohe'] = array(df_twoclasses['Age'])
#integer encode
label_encoder = LabelEncoder()
age_encoded = label_encoder.fit_transform(df_twoclasses['age_ohe'])
df_twoclasses['age_ohe'] = array(age_encoded)

#Dropping original Age column
df_twoclasses = df_twoclasses.drop("Age",1)

"""#### Iterative Imputer"""

# iterative imputation transform
from numpy import isnan
from pandas import read_csv
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

data = df_twoclasses.values
ix = [i for i in range(data.shape[1]) if i != 0]
X, y = data[:, ix], data[:, 0]
# print total missing
print('Missing: %d' % sum(isnan(X).flatten()))
# define imputer
imputer = IterativeImputer(max_iter = 50, skip_complete = True)
# fit on the dataset
imputer.fit(X)
# transform the dataset
Xtrans = imputer.transform(X)
# print total missing
print('Missing: %d' % sum(isnan(Xtrans).flatten()))

from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
# define modeling pipeline
model = RandomForestClassifier()
imputer = IterativeImputer()
pipeline = Pipeline(steps=[('i', imputer), ('m', model)])

from numpy import mean
from numpy import std
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
# define model evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate model
scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')
print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

feature_cols = ['Fever', 'Duration_of_pain', 'Sick_leave',
       'Earlier_hospitalization', 'Familiy_history', 'Depression',
       'Extremely_nervous', 'Stress', 'Irrational_thoughts_risk_lasting',
       'Coping_strategy', 'Kinesiophobia_physical_exercise',
       'Kinesiophobia_pain_stop', 'Uses_analgesics',
       'Uses_corticosteroids', 'Serious_disease', 'Neurogenic_signals',
       'Continuous_pain', 'Decreased_mobility', 'Nocturnal_pain',
       'Weightloss_per_year', 'Loss_muscle_strength', 'Failure_symptoms',
       'neck_pain_intensity', 'low_back_pain_intensity',
       'arm_left_pain_intensity', 'arm_right_pain_intensity',
       'leg_left_pain_intensity', 'leg_right_pain_intensity', 'Paidwork',
       'age_ohe']
X = df_twoclasses[feature_cols] # Features
y = df_twoclasses.Treatment # Target variable

X = pd.DataFrame(Xtrans, columns = feature_cols)

"""###Standard Scaling Data"""

from sklearn.preprocessing import StandardScaler
x = X.loc[:, feature_cols].values
#y = df_new.loc[:,['Treatment']].values
x = StandardScaler().fit_transform(x)
X = pd.DataFrame(x, columns = feature_cols)

"""### Over and Undersampling"""

# Generate and plot a synthetic imbalanced classification dataset
from collections import Counter
from sklearn.datasets import make_classification
from matplotlib import pyplot
from numpy import where
from imblearn.over_sampling import SMOTE

# summarize class distribution
counter = Counter(y)
print(counter)

from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline

over = SMOTE()
under = RandomUnderSampler()

steps = [('o', over), ('u', under)]
pipeline = Pipeline(steps=steps)

# transform the dataset
X, y = pipeline.fit_resample(X, y)

# summarize the new class distribution
counter = Counter(y)
print(counter)

"""###Split data"""

# split data into train and test sets
from sklearn.model_selection import train_test_split
seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)

"""##Random forest"""

# Random  forest
from sklearn.ensemble import RandomForestClassifier
# Instantiate model with 1000 decision trees
rf_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)
# Train the model on training data
rd_model = rf_model.fit(X_train, y_train)

# make predictions for test data
y_pred = rf_model.predict(X_test)
predictions = [round(value) for value in y_pred]
# Calculate the absolute errors
errors = abs(predictions - y_test)
# Print out the mean absolute error (mae)
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

# evaluate predictions
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, predictions)
cnf_matrix

#classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

"""##XG Boost model"""

from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# fit model no training data
model = XGBClassifier()
model.fit(X_train, y_train)

# make predictions for test data
y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""###K-Fold Cross Validation"""

from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# prepare the cross-validation procedure
cv = KFold(n_splits=10, random_state=1, shuffle=True)

# evaluate model
scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
# report performance
print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

"""#Multi-class classification using 4 classes and combining 1 and 5

##Pre-processing of data

### Read data
"""

df = pd.read_excel(io.BytesIO(uploaded.get("Dataset - LBP RA.xlsx")),  sheet_name = "Training Dataset")
var = pd.read_excel(io.BytesIO(uploaded.get("Dataset - LBP RA.xlsx")),  sheet_name = "Variables")

"""### Dropping columns with more than 15% missing values"""

#Data Completeness percentage
(df.count()/1546*100).sort_values()

df_new = df.drop("Irrational_thoughts_work",1)
df_new = df_new.drop("Incoordination",1)
df_new = df_new.drop("Relationship_with_colleagues",1)
df_new = df_new.drop("Trauma",1)
df_new = df_new.drop("working_ability",1)
df_new = df_new.drop("Workoverload",1)

"""###Combine classes 1 and 5 into 1 outpout class

"""

#df_fourclasses = df_new[(df_new.Treatment != 2) & (df_new.Treatment != 3) & (df_new.Treatment != 4)]
df_fourclasses = df_new
df_fourclasses.loc[(df_fourclasses.Treatment == 1),'Treatment']=6
df_fourclasses.loc[(df_fourclasses.Treatment == 5),'Treatment']=6

df_fourclasses.Treatment.unique()

"""### Impute Missing Values

#####One-hot Encoding Age column
"""

#One-hot encode age
#One hot encoding
from numpy import array
from numpy import argmax
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

#Age encoding
df_fourclasses['age_ohe'] = array(df_fourclasses['Age'])
#integer encode
label_encoder = LabelEncoder()
age_encoded = label_encoder.fit_transform(df_fourclasses['age_ohe'])
df_fourclasses['age_ohe'] = array(age_encoded)

#Dropping original Age column
df_fourclasses = df_fourclasses.drop("Age",1)

"""#### Iterative Imputer"""

# iterative imputation transform
from numpy import isnan
from pandas import read_csv
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

data = df_fourclasses.values
ix = [i for i in range(data.shape[1]) if i != 0]
X, y = data[:, ix], data[:, 0]
# print total missing
print('Missing: %d' % sum(isnan(X).flatten()))
# define imputer
imputer = IterativeImputer(max_iter = 50, skip_complete = True)
# fit on the dataset
imputer.fit(X)
# transform the dataset
Xtrans = imputer.transform(X)
# print total missing
print('Missing: %d' % sum(isnan(Xtrans).flatten()))

from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
# define modeling pipeline
model = RandomForestClassifier()
imputer = IterativeImputer()
pipeline = Pipeline(steps=[('i', imputer), ('m', model)])

from numpy import mean
from numpy import std
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
# define model evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate model
scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')
print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

feature_cols = ['Fever', 'Duration_of_pain', 'Sick_leave',
       'Earlier_hospitalization', 'Familiy_history', 'Depression',
       'Extremely_nervous', 'Stress', 'Irrational_thoughts_risk_lasting',
       'Coping_strategy', 'Kinesiophobia_physical_exercise',
       'Kinesiophobia_pain_stop', 'Uses_analgesics',
       'Uses_corticosteroids', 'Serious_disease', 'Neurogenic_signals',
       'Continuous_pain', 'Decreased_mobility', 'Nocturnal_pain',
       'Weightloss_per_year', 'Loss_muscle_strength', 'Failure_symptoms',
       'neck_pain_intensity', 'low_back_pain_intensity',
       'arm_left_pain_intensity', 'arm_right_pain_intensity',
       'leg_left_pain_intensity', 'leg_right_pain_intensity', 'Paidwork',
       'age_ohe']
X = df_fourclasses[feature_cols] # Features
y = df_fourclasses.Treatment # Target variable

X = pd.DataFrame(Xtrans, columns = feature_cols)

"""###Standard Scaling Data"""

from sklearn.preprocessing import StandardScaler
x = X.loc[:, feature_cols].values
#y = df_new.loc[:,['Treatment']].values
x = StandardScaler().fit_transform(x)
X = pd.DataFrame(x, columns = feature_cols)

"""### Over and Undersampling"""

# Generate and plot a synthetic imbalanced classification dataset
from collections import Counter
from sklearn.datasets import make_classification
from matplotlib import pyplot
from numpy import where
from imblearn.over_sampling import SMOTE

# summarize class distribution
counter = Counter(y)
print(counter)

from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline

over = SMOTE()
under = RandomUnderSampler()

steps = [('o', over), ('u', under)]
pipeline = Pipeline(steps=steps)

# transform the dataset
X, y = pipeline.fit_resample(X, y)

# summarize the new class distribution
counter = Counter(y)
print(counter)

"""###Split data"""

# split data into train and test sets
from sklearn.model_selection import train_test_split
seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)

"""##Random forest"""

# Random  forest
from sklearn.ensemble import RandomForestClassifier
# Instantiate model with 1000 decision trees
rf_model = RandomForestClassifier(n_estimators = 1000, random_state = 42)
# Train the model on training data
rd_model = rf_model.fit(X_train, y_train)

# make predictions for test data
y_pred = rf_model.predict(X_test)
predictions = [round(value) for value in y_pred]
# Calculate the absolute errors
errors = abs(predictions - y_test)
# Print out the mean absolute error (mae)
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

# evaluate predictions
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

#make confusion matrix
from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, predictions)
cnf_matrix

#classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))

"""##XG Boost model"""

from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# fit model no training data
model = XGBClassifier()
model.fit(X_train, y_train)

# make predictions for test data
y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""###K-Fold Cross Validation"""

from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# prepare the cross-validation procedure
cv = KFold(n_splits=10, random_state=1, shuffle=True)

# evaluate model
scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
# report performance
print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

"""#Multi-class classification using 4 classes and combining 1 and 5 without oversampling

##Pre-processing of data

### Read data
"""

df = pd.read_excel(io.BytesIO(uploaded.get("Dataset - LBP RA.xlsx")),  sheet_name = "Training Dataset")
var = pd.read_excel(io.BytesIO(uploaded.get("Dataset - LBP RA.xlsx")),  sheet_name = "Variables")

"""### Dropping columns with more than 15% missing values"""

#Data Completeness percentage
(df.count()/1546*100).sort_values()

df_new = df.drop("Irrational_thoughts_work",1)
df_new = df_new.drop("Incoordination",1)
df_new = df_new.drop("Relationship_with_colleagues",1)
df_new = df_new.drop("Trauma",1)
df_new = df_new.drop("working_ability",1)
df_new = df_new.drop("Workoverload",1)

"""###Combine classes 1 and 5 into 1 outpout class

"""

#df_fourclasses = df_new[(df_new.Treatment != 2) & (df_new.Treatment != 3) & (df_new.Treatment != 4)]
df_fourclasses = df_new
df_fourclasses.loc[(df_fourclasses.Treatment == 1),'Treatment']=6
df_fourclasses.loc[(df_fourclasses.Treatment == 5),'Treatment']=6

df_fourclasses.Treatment.unique()

"""### Impute Missing Values

#####One-hot Encoding Age column
"""

#One-hot encode age
#One hot encoding
from numpy import array
from numpy import argmax
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

#Age encoding
df_fourclasses['age_ohe'] = array(df_fourclasses['Age'])
#integer encode
label_encoder = LabelEncoder()
age_encoded = label_encoder.fit_transform(df_fourclasses['age_ohe'])
df_fourclasses['age_ohe'] = array(age_encoded)

#Dropping original Age column
df_fourclasses = df_fourclasses.drop("Age",1)

"""#### Iterative Imputer"""

# iterative imputation transform
from numpy import isnan
from pandas import read_csv
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

data = df_fourclasses.values
ix = [i for i in range(data.shape[1]) if i != 0]
X, y = data[:, ix], data[:, 0]
# print total missing
print('Missing: %d' % sum(isnan(X).flatten()))
# define imputer
imputer = IterativeImputer(max_iter = 50, skip_complete = True)
# fit on the dataset
imputer.fit(X)
# transform the dataset
Xtrans = imputer.transform(X)
# print total missing
print('Missing: %d' % sum(isnan(Xtrans).flatten()))

from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
# define modeling pipeline
model = RandomForestClassifier()
imputer = IterativeImputer()
pipeline = Pipeline(steps=[('i', imputer), ('m', model)])

from numpy import mean
from numpy import std
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
# define model evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# evaluate model
scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')
print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

feature_cols = ['Fever', 'Duration_of_pain', 'Sick_leave',
       'Earlier_hospitalization', 'Familiy_history', 'Depression',
       'Extremely_nervous', 'Stress', 'Irrational_thoughts_risk_lasting',
       'Coping_strategy', 'Kinesiophobia_physical_exercise',
       'Kinesiophobia_pain_stop', 'Uses_analgesics',
       'Uses_corticosteroids', 'Serious_disease', 'Neurogenic_signals',
       'Continuous_pain', 'Decreased_mobility', 'Nocturnal_pain',
       'Weightloss_per_year', 'Loss_muscle_strength', 'Failure_symptoms',
       'neck_pain_intensity', 'low_back_pain_intensity',
       'arm_left_pain_intensity', 'arm_right_pain_intensity',
       'leg_left_pain_intensity', 'leg_right_pain_intensity', 'Paidwork',
       'age_ohe']
X = df_fourclasses[feature_cols] # Features
y = df_fourclasses.Treatment # Target variable

X = pd.DataFrame(Xtrans, columns = feature_cols)

"""###Standard Scaling Data"""

from sklearn.preprocessing import StandardScaler
x = X.loc[:, feature_cols].values
#y = df_new.loc[:,['Treatment']].values
x = StandardScaler().fit_transform(x)
X = pd.DataFrame(x, columns = feature_cols)

"""###Split data"""

# split data into train and test sets
from sklearn.model_selection import train_test_split
seed = 7
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)

"""##XG Boost model"""

from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# fit model no training data
model = XGBClassifier()
model.fit(X_train, y_train)

# make predictions for test data
y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]

# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

from sklearn import metrics
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""###K-Fold Cross Validation"""

from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# prepare the cross-validation procedure
cv = KFold(n_splits=10, random_state=1, shuffle=True)

# evaluate model
scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
# report performance
print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))